{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Challenge Project Work CO2\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "###### Ka Men Ho, Luana Aido da Silva, Michèle Pfister\n",
    "\n",
    "The project explores the performance of machine learning (ML) algorithms for the prediction and diagnosis of heart disease. As heart disease remains one of the leading causes of mortality worldwide, in this data challenge project we aim to understand, how early detection strategies can be improved using these tools, which have the potential to enhance patient outcomes and reduce disease-related mortality (Alshenawy, 2024).\n",
    "\n",
    "The underlying biological mechanisms of heart attacks and strokes involve obstruction of blood flow to the heart or brain due to arterial plaque accumulation or thrombus formation. A major clinical challenge is that symptoms of heart disease are often nonspecific, overlapping with those of other conditions or being misattributed to normal aging, which complicates preventive and accurate diagnosis (Quah et al., 2014).\n",
    "\n",
    "Machine learning has become an increasingly important tool in healthcare, enhancing clinical decision-making in disease prediction and diagnosis. Traditional approaches relied largely on practitioners’ interpretation of a patient’s medical history, reported symptoms, and physical examination findings (Karthick et al., 2022).\n",
    "\n",
    "The dataset used in this project was obtained from the University of California Irvine (UCI) Machine Learning Repository and is widely employed for heart disease prediction tasks. Patient outcomes were determined using cardiac catheterization, considered the clinical gold standard, where individuals exhibiting more than 50% narrowing of a coronary artery were classified as having heart disease.\n",
    "The dataset comprises 270 patient records and includes 13 independent predictive variables. Detailed descriptions of these attributes are provided in the UCI repository documentation (University of California, Irvine, n.d.)\n",
    "\n",
    "An updated version of the heart disease dataset includes 303 consecutive patients referred for coronary angiography at the Cleveland Clinic in Cleveland, Ohio, between May 1981 and September 1984. This cohort was used to develop the Cleveland algorithm, a computerized diagnostic model whose regression coefficients were later validated using independent patient populations from Budapest, Long Beach, and Switzerland.\n",
    "The Cleveland cohort had a mean age of 54 years, consisted of 68% men, and showed a disease prevalence of 46%. The model was derived from 13 clinical and test-related variables, with age, sex, chest pain type, and systolic blood pressure identified as key predictors. Chest pain was categorized as typical anginal, atypical anginal, nonanginal, or asymptomatic, and inclusion of age, sex, and chest pain type was required for clinically relevant disease probability estimation.\n",
    "\n",
    "Because complete joint distributions of clinical variables were rarely available, the original model assumed independence among predictors. However, previous research has shown that ignoring interdependencies between symptoms can result in overconfident predictions and inaccurate disease probability estimates (Detrano et al., 1989). \n",
    "\n",
    "To mitigate the overconfidence that can arise from assuming independence among clinical variables, the study of Kathleen employs an ensemble learning approach using the Adaptive Boosting (AdaBoost) algorithm. AdaBoost is a meta-learning method that combines multiple weak classifiers into a single, more robust predictive model. Through 100 iterative boosting rounds, the algorithm adaptively increases the weight of observations that were misclassified in previous iterations, encouraging subsequent classifiers to focus on complex or interacting symptom patterns that are difficult to capture with a single model. The final prediction is produced via a weighted majority vote of all component classifiers, resulting in a classifier that is less prone to overconfident assumptions and better aligned with the true diagnostic outcome (Kathleen et al., 2016).\n",
    "\n",
    "Alshenawy (2024) evaluated several machine learning algorithms, both individually and in ensemble settings, to identify reliable approaches for heart disease diagnosis. The models analyzed included Support Vector Machines, Random Forest, Decision Trees, Naïve Bayes, and Logistic Regression as a baseline. The data were divided into training (189 observations) and testing (81 observations) sets, and model performance was assessed using multiple metrics, including accuracy, sensitivity, specificity, and AUC.\n",
    "\n",
    "Among the individual models, Random Forest achieved the highest overall performance, while ensemble approaches using bagging produced comparable but not superior results. Building on this framework, the data challenge project work CO2 applies a similar comparative evaluation of multiple machine learning models, with particular emphasis on ensemble methods, to assess their effectiveness in heart disease prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "\n",
    "- 1. Introduction\n",
    "\n",
    "- 2. Exploratory data analysis\n",
    "- 2. 1 Importing Libraries and load the data\n",
    "- 3. Preprocessing\n",
    "- 3. 1 Cleaning the data \n",
    "- 3. 2 Handling missing values\n",
    "- 3. 3 Converting text labels to numbers (feature encoding)\n",
    "- 4. Modelling\n",
    "- 4. 1 symple base-line model\n",
    "- 4. 2 two sophisticated model approaches\n",
    "- 4. 3 Experiment and testing the model\n",
    "- 5. Results\n",
    "- 6. Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory data analysis\n",
    "\n",
    "Analyse your data. Visualise and explain the data features you deem to be relevant for\n",
    "the project.\n",
    "\n",
    "### 2.1 Importing Libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "heart_data = pd.read_csv(\"Heart_Disease_Prediction.csv\")\n",
    "\n",
    "heart_data.head()\n",
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "Explain what kind of preprocessing, feature encoding you are applying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the 'id' column\n",
    "heart_data = heart_data.drop(columns=['index'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                          int64\n",
       "Sex                          int64\n",
       "Chest pain type              int64\n",
       "BP                           int64\n",
       "Cholesterol                  int64\n",
       "FBS over 120                 int64\n",
       "EKG results                  int64\n",
       "Max HR                       int64\n",
       "Exercise angina              int64\n",
       "ST depression              float64\n",
       "Slope of ST                  int64\n",
       "Number of vessels fluro      int64\n",
       "Thallium                     int64\n",
       "Heart Disease               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Chest pain type</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FBS over 120</th>\n",
       "      <th>EKG results</th>\n",
       "      <th>Max HR</th>\n",
       "      <th>Exercise angina</th>\n",
       "      <th>ST depression</th>\n",
       "      <th>Slope of ST</th>\n",
       "      <th>Number of vessels fluro</th>\n",
       "      <th>Thallium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.00000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.433333</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>3.174074</td>\n",
       "      <td>131.344444</td>\n",
       "      <td>249.659259</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>149.677778</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>1.05000</td>\n",
       "      <td>1.585185</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>4.696296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.109067</td>\n",
       "      <td>0.468195</td>\n",
       "      <td>0.950090</td>\n",
       "      <td>17.861608</td>\n",
       "      <td>51.686237</td>\n",
       "      <td>0.355906</td>\n",
       "      <td>0.997891</td>\n",
       "      <td>23.165717</td>\n",
       "      <td>0.470952</td>\n",
       "      <td>1.14521</td>\n",
       "      <td>0.614390</td>\n",
       "      <td>0.943896</td>\n",
       "      <td>1.940659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.60000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.20000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex  Chest pain type          BP  Cholesterol  \\\n",
       "count  270.000000  270.000000       270.000000  270.000000   270.000000   \n",
       "mean    54.433333    0.677778         3.174074  131.344444   249.659259   \n",
       "std      9.109067    0.468195         0.950090   17.861608    51.686237   \n",
       "min     29.000000    0.000000         1.000000   94.000000   126.000000   \n",
       "25%     48.000000    0.000000         3.000000  120.000000   213.000000   \n",
       "50%     55.000000    1.000000         3.000000  130.000000   245.000000   \n",
       "75%     61.000000    1.000000         4.000000  140.000000   280.000000   \n",
       "max     77.000000    1.000000         4.000000  200.000000   564.000000   \n",
       "\n",
       "       FBS over 120  EKG results      Max HR  Exercise angina  ST depression  \\\n",
       "count    270.000000   270.000000  270.000000       270.000000      270.00000   \n",
       "mean       0.148148     1.022222  149.677778         0.329630        1.05000   \n",
       "std        0.355906     0.997891   23.165717         0.470952        1.14521   \n",
       "min        0.000000     0.000000   71.000000         0.000000        0.00000   \n",
       "25%        0.000000     0.000000  133.000000         0.000000        0.00000   \n",
       "50%        0.000000     2.000000  153.500000         0.000000        0.80000   \n",
       "75%        0.000000     2.000000  166.000000         1.000000        1.60000   \n",
       "max        1.000000     2.000000  202.000000         1.000000        6.20000   \n",
       "\n",
       "       Slope of ST  Number of vessels fluro    Thallium  \n",
       "count   270.000000               270.000000  270.000000  \n",
       "mean      1.585185                 0.670370    4.696296  \n",
       "std       0.614390                 0.943896    1.940659  \n",
       "min       1.000000                 0.000000    3.000000  \n",
       "25%       1.000000                 0.000000    3.000000  \n",
       "50%       2.000000                 0.000000    3.000000  \n",
       "75%       2.000000                 1.000000    7.000000  \n",
       "max       3.000000                 3.000000    7.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                        0\n",
       "Sex                        0\n",
       "Chest pain type            0\n",
       "BP                         0\n",
       "Cholesterol                0\n",
       "FBS over 120               0\n",
       "EKG results                0\n",
       "Max HR                     0\n",
       "Exercise angina            0\n",
       "ST depression              0\n",
       "Slope of ST                0\n",
       "Number of vessels fluro    0\n",
       "Thallium                   0\n",
       "Heart Disease              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Converting text labels to numbers (feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Target encoding for absence and presence of heart disease\n",
    "\n",
    "## Feature encoding for binary categorical features and continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "what needs to be encoded:\n",
    "    Sex binary          category\n",
    "    Chest pain type     unordered categories\n",
    "    FBS over 120        binary\n",
    "    EKG results         categories\n",
    "    Exercise angina     binary\n",
    "    Slope of ST         categories\n",
    "    Thallium            categories\n",
    "\n",
    "do not one hot enocde:\n",
    "Age                         continuous\n",
    "BP\n",
    "Cholesterol\n",
    "Max HR\n",
    "ST depression\n",
    "Number of vessels fluro     ordered count (0–3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 1 symple base-line model\n",
    "\n",
    "perfect model setup for baseline: Logicstic regression\n",
    "\n",
    "is interpretable, medically standard and easy to explain coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 2 two sophisticated model approaches\n",
    "\n",
    "number 1 random forest: captures feature interactions, non linear splits, robust on small datasets\n",
    "\n",
    "numeber 2 Gradient Boosting or SVM (RBF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources\n",
    "\n",
    "Alshenawy, F. (2024). Using Machine Learning Algorithms to improve heart disease diagnoses. المجلة العلمية للدراسات والبحوث المالية والتجارية, 5(1), 417–442. https://doi.org/10.21608/cfdj.2024.324103\n",
    "\n",
    "Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J.-J., Sandhu, S., Guppy, K. H., Lee, S., & Froelicher, V. (1989). International application of a new probability algorithm for the diagnosis of coronary artery disease. The American Journal of Cardiology, 64(5), 304–310. https://doi.org/10.1016/0002-9149(89)90524-9\n",
    "\n",
    "Kathleen, H., H., J., & J., G. (2016). Diagnosing Coronary Heart Disease using Ensemble Machine Learning. International Journal of Advanced Computer Science and Applications, 7(10). https://doi.org/10.14569/IJACSA.2016.071004\n",
    "\n",
    "Karthick, K., Aruna, S. K., & Manikandan, R. (2022). Development and evaluation of the bootstrap resampling technique based statistical prediction model for Covid-19 real time data : A data driven approach. Journal of Interdisciplinary Mathematics, 25(3), 615–627. https://doi.org/10.1080/09720502.2021.2012890\n",
    "\n",
    "Quah, J. L. J., Yap, S., Cheah, S. O., Ng, Y. Y., Goh, E. S., Doctor, N., Leong, B. S.-H., Tiah, L., Chia, M. Y. C., & Ong, M. E. H. (2014). Knowledge of Signs and Symptoms of Heart Attack and Stroke among Singapore Residents. BioMed Research International, 2014, 1–8. https://doi.org/10.1155/2014/572425\n",
    "\n",
    "University of California, Irvine. (n.d.). Heart disease data set. UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/Heart+Disease"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCO2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
